# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Runs archetypal analysis (AA)
#'
#' @param A Input matrix.
#' @param W0 Matrix with <em>k</em> columns representing initial archetypes.
#' @param max_it Maximum number of iterations.
#' @param tol Convergence tolerance.
#'
#' @return Field with matrices <b>C</b> (<b>A.n_cols</b> x <em>k</em>) and <b>H</b> (<em>k</em> x <b>A.n_cols</b>).
#'
#' @examples
#' S_r = t(reducedDims(ace)$ACTION)
#' SPA.out = runSPA(S_r, 10)
#' W0 = S_r[, SPA.selected_cols]
#' AA.out = runAA(S_r, W0)
#' H = AA.out$H
#' cell.assignments = apply(H, 2, which.max)
C_runAA <- function(A, W0, max_it = 100L, tol = 1e-6) {
    .Call(`_actionet_C_runAA`, A, W0, max_it, tol)
}

#' Run ACTION decomposition algorithm
#'
#' @param S_r Input matrix. Usually a reduced representation of the raw data.
#' @param k_min Minimum number of archetypes (>= 2) to search for, and the beginning of the search range.
#' @param k_max Maximum number of archetypes (<= <b>S_r.n_cols</b>) to search for, and the end of the search range.
#' @param normalization Normalization method to apply on <b>S_r</b> before running ACTION.
#' @param max_it Maximum number of iterations for <code>runAA()</code>.
#' @param tol Convergence tolerance for <code>runAA()</code>.
#' @param thread_no Number of CPU threads to use. If 0, number is automatically determined.
#'
#' @return A named list with entries 'C' and 'H', each a list for different values of k
#'
#' @examples
#' ACTION.out = runACTION(S_r, k_max = 10)
#' H8 = ACTION.out$H[[8]]
#' cell.assignments = apply(H8, 2, which.max)
C_decompACTION <- function(S_r, k_min = 2L, k_max = 30L, max_it = 100L, tol = 1e-16, thread_no = 0L) {
    .Call(`_actionet_C_decompACTION`, S_r, k_min, k_max, max_it, tol, thread_no)
}

C_runACTION <- function(S_r, k_min = 2L, k_max = 30L, max_it = 100L, tol = 1e-16, spec_th = -3, min_obs = 3L, thread_no = 0L) {
    .Call(`_actionet_C_runACTION`, S_r, k_min, k_max, max_it, tol, spec_th, min_obs, thread_no)
}

#' Filter and aggregate multi-level archetypes
#'
#' @param C_trace Field containing C matrices. Output of <code>runACTION()</code> in <code>ResACTION["C"]</code>.
#' @param H_trace Field containing H matrices. Output of <code>runACTION()</code> in <code>ResACTION["H"]</code>.
#' @param spec_th Minimum threshold (as z-score) to filter archetypes by specificity.
#' @param min_obs Minimum number of observations assigned to an archetypes needed to retain that archetype.
#'
#' @return A named list: \itemize{
#' \item selected_archs: List of final archetypes that passed the
#' filtering/pruning step.
#' \item C_stacked,H_stacked: Horizontal/Vertical
#' concatenation of filtered C and H matrices, respectively.
#' }
#'
#' @examples
#' S = logcounts(sce)
#' reduction.out = reduce(S, reduced_dim = 50)
#' S_r = reduction.out$S_r
#' ACTION.out = runACTION(S_r, k_max = 10)
#' reconstruction.out = reconstruct_archetypes(S, ACTION.out$C, ACTION.out$H)
C_collectArchetypes <- function(C_trace, H_trace, spec_th = -3, min_obs = 3L) {
    .Call(`_actionet_C_collectArchetypes`, C_trace, H_trace, spec_th, min_obs)
}

#' Identify and merge redundant archetypes into a representative subset
#'
#' @param S_r Reduced data matrix from which archetypes were found.
#' @param C_stacked Concatenated (and filtered) <code>C</code> (<b>S_r.n</b> x <em>n</em>) matrix.
#' Output of <code>collectArchetypes()</code> in <code>ResCollectArch["C_stacked"]</code>.
#' @param H_stacked Concatenated (and filtered) <code>H</code> (<b>S_r.n</b> x <em>n</em>) matrix.
#' Output of <code>collectArchetypes()</code> in <code>ResCollectArch["H_stacked"]</code>.
#' @param normalization Normalization method to apply to <b>S_r</b>.
#' @param thread_no Number of CPU threads to use. If 0, number is automatically determined.
#'
#' @return A named list: \itemize{
#' \item archetype_groups: Equivalent classes of archetypes (non-redundant)
#' \item C_merged,H_merged: C and H matrices of merged archetypes
#' \item sample_assignments: Assignment of samples/cells to merged archetypes
#' }
#' @examples
#' prune.out = collectArchetypes(ACTION.out$C, ACTION.out$H)
#'	G = buildNetwork(prune.out$H_stacked)
#' unification.out = mergeArchetypes(G, S_r, prune.out$C_stacked, prune.out$H_stacked)
#' cell.clusters = unification.out$sample_assignments
C_mergeArchetypes <- function(S_r, C_stacked, H_stacked, thread_no = 0L) {
    .Call(`_actionet_C_mergeArchetypes`, S_r, C_stacked, H_stacked, thread_no)
}

#' Compute reduced kernel matrix
#'
#' @param S Input matrix (<em>vars</em> x <em>obs</em>).
#' May be <code>arma::mat</code> or <code>arma::sp_mat</code>.
#' @param dim Number of singular vectors to estimate. Passed to <code>runSVD()</code>.
#' @param svd_alg Singular value decomposition algorithm. See to <code>runSVD()</code> for options.
#' @param max_it Maximum number of iterations. Passed to <code>runSVD()</code>.
#' @param seed Random seed.
#' @param verbose Print status messages.
#'
#' @return Field with 5 elements:
#' - 0: <code>arma::mat</code> Reduced kernel matrix.
#' - 1: <code>arma::vec</code> Singular values.
#' - 2: <code>arma::mat</code> Left singular vectors.
#' - 3: <code>arma::mat</code> <b>A</b> perturbation matrix.
#' - 4: <code>arma::mat</code> <b>B</b> perturbation matrix.
#'
#' @examples
#' S = logcounts(sce)
#' reduction.out = reduce(S, reduced_dim = 50)
#' S_r = reduction.out$S_r
C_reduceKernelSparse <- function(S, k = 50L, svd_alg = 0L, max_it = 0L, seed = 0L, verbose = TRUE) {
    .Call(`_actionet_C_reduceKernelSparse`, S, k, svd_alg, max_it, seed, verbose)
}

C_reduceKernelDense <- function(S, k = 50L, svd_alg = 0L, max_it = 0L, seed = 0L, verbose = TRUE) {
    .Call(`_actionet_C_reduceKernelDense`, S, k, svd_alg, max_it, seed, verbose)
}

#' Solves min_{X} (|| AX - B ||) s.t. simplex constraint
#'
#' @param A Input matrix <em>A</em> in <em>AX - B</em>.
#' @param B Inout matrix <em>B</em> in <em>AX - B</em>.
#' @param computeXtX Return <em>Xt(X)</em>
#'
#' @return X Solution
#'
#' @examples
#' C = ACTION.out$C[[10]]
#' A = S_r %*% C
#' B = S_r
#' H = runSimplexRegression(A, B)
C_runSimplexRegression <- function(A, B, computeXtX = FALSE) {
    .Call(`_actionet_C_runSimplexRegression`, A, B, computeXtX)
}

#' Run successive projections algorithm (SPA) to solve separable NMF
#'
#' @param A Input matrix.
#' @param k Number of candidate vertices to solve for.
#'
#' @return A named list with entries 'selected_cols' and 'norms'
#' @examples
#' H = runSPA(S_r, 10)
C_runSPA <- function(A, k) {
    .Call(`_actionet_C_runSPA`, A, k)
}

C_computeFeatureStats <- function(G, S, X, norm_method = 2L, alpha = 0.85, max_it = 5L, approx = FALSE, thread_no = 0L, ignore_baseline = FALSE) {
    .Call(`_actionet_C_computeFeatureStats`, G, S, X, norm_method, alpha, max_it, approx, thread_no, ignore_baseline)
}

C_computeFeatureStatsVision <- function(G, S, X, norm_method = 2L, alpha = 0.85, max_it = 5L, approx = FALSE, thread_no = 0L) {
    .Call(`_actionet_C_computeFeatureStatsVision`, G, S, X, norm_method, alpha, max_it, approx, thread_no)
}

#' Compute feature specificity (from archetype footprints)
#'
#' @param S Input matrix (sparseMatrix)
#' @param H A soft membership matrix - Typically H_merged from the mergeArchetypes() function.
#'
#' @return A list with the over/under-logPvals
#'
#' @examples
#' prune.out = collectArchetypes(ACTION.out$C, ACTION.out$H)
#'	G = buildNetwork(prune.out$H_stacked)
#' unification.out = mergeArchetypes(G, S_r, prune.out$C_stacked, prune.out$H_stacked)
#' cell.clusters = unification.out$sample_assignments
#' S.norm = renormalize_input_matrix(S, cell.clusters)
#' logPvals.list = compute_archetype_feature_specificity(S.norm, unification.out$H_merged)
#' specificity.scores = logPvals.list$upper_significance
C_archetypeFeatureSpecificitySparse <- function(S, H, thread_no = 0L) {
    .Call(`_actionet_C_archetypeFeatureSpecificitySparse`, S, H, thread_no)
}

C_archetypeFeatureSpecificityDense <- function(S, H, thread_no = 0L) {
    .Call(`_actionet_C_archetypeFeatureSpecificityDense`, S, H, thread_no)
}

#' Compute feature specificity (from cluster assignments)
#'
#' @param S Input matrix ("sparseMatrix")
#' @param sample_assignments Vector of cluster assignments
#'
#' @return A list with the over/under-logPvals
#'
#' @examples
#' prune.out = collectArchetypes(ACTION.out$C, ACTION.out$H)
#'	G = buildNetwork(prune.out$H_stacked)
#' unification.out = mergeArchetypes(G, S_r, prune.out$C_stacked, prune.out$H_stacked)
#' cell.clusters = unification.out$sample_assignments
#' S.norm = renormalize_input_matrix(S, cell.clusters)
#' logPvals.list = compute_cluster_feature_specificity(S.norm, cell.clusters)
#' specificity.scores = logPvals.list$upper_significance
C_computeFeatureSpecificitySparse <- function(S, labels, thread_no = 0L) {
    .Call(`_actionet_C_computeFeatureSpecificitySparse`, S, labels, thread_no)
}

C_computeFeatureSpecificityDense <- function(S, labels, thread_no = 0L) {
    .Call(`_actionet_C_computeFeatureSpecificityDense`, S, labels, thread_no)
}

C_orthogonalizeBatchEffect <- function(S, old_S_r, old_V, old_A, old_B, old_sigma, design) {
    .Call(`_actionet_C_orthogonalizeBatchEffect`, S, old_S_r, old_V, old_A, old_B, old_sigma, design)
}

C_orthogonalizeBatchEffect_full <- function(S, old_S_r, old_V, old_A, old_B, old_sigma, design) {
    .Call(`_actionet_C_orthogonalizeBatchEffect_full`, S, old_S_r, old_V, old_A, old_B, old_sigma, design)
}

C_orthogonalizeBasal <- function(S, old_S_r, old_V, old_A, old_B, old_sigma, basal) {
    .Call(`_actionet_C_orthogonalizeBasal`, S, old_S_r, old_V, old_A, old_B, old_sigma, basal)
}

C_orthogonalizeBasal_full <- function(S, old_S_r, old_V, old_A, old_B, old_sigma, basal) {
    .Call(`_actionet_C_orthogonalizeBasal_full`, S, old_S_r, old_V, old_A, old_B, old_sigma, basal)
}

#' Computes SVD decomposition
#'
#' This is direct implementation of the randomized SVD algorithm:
#' From: IRLBA R Package
#'
#' @param A Input matrix ("sparseMatrix")
#' @param k Dimension of SVD decomposition
#' @param max_it Number of iterations (default=5)
#' @param seed Random seed (default=0)
#' @param algorithm SVD algorithm to use. Currently supported methods are blah blah blah
#'
#' @return A named list with U, sigma, and V components
#'
#' @examples
#' A = randn(100, 20)
#' svd.out = runSVD(A, dim = 3)
#' U = svd.out$u
C_runSVDSparse <- function(A, k = 30L, max_it = 0L, seed = 0L, algorithm = 0L, verbose = TRUE) {
    .Call(`_actionet_C_runSVDSparse`, A, k, max_it, seed, algorithm, verbose)
}

C_runSVDDense <- function(A, k = 30L, max_it = 0L, seed = 0L, algorithm = 0L, verbose = TRUE) {
    .Call(`_actionet_C_runSVDDense`, A, k, max_it, seed, algorithm, verbose)
}

C_perturbedSVD <- function(u, d, v, A, B) {
    .Call(`_actionet_C_perturbedSVD`, u, d, v, A, B)
}

#' Builds an interaction network from the multi-level archetypal decompositions
#'
#' @param H_stacked Output of the collectArchetypes() function.
#' @param density Overall density of constructed graph. The higher the density,
#' the more edges are retained (default = 1.0).
#' @param thread_no Number of parallel threads (default = 0).
#' @param mutual_edges_only Symmetrization strategy for nearest-neighbor edges.
#' If it is true, only mutual nearest-neighbors are returned (default=TRUE).
#'
#' @return G Adjacency matrix of the ACTIONet graph.
#'
#' @examples
#' prune.out = collectArchetypes(ACTION.out$C, ACTION.out$H)
#'	G = buildNetwork(prune.out$H_stacked)
C_buildNetwork <- function(H, algorithm = "k*nn", distance_metric = "jsd", density = 1.0, thread_no = 0L, M = 16, ef_construction = 200, ef = 50, mutual_edges_only = TRUE, k = 10L) {
    .Call(`_actionet_C_buildNetwork`, H, algorithm, distance_metric, density, thread_no, M, ef_construction, ef, mutual_edges_only, k)
}

C_runLPA <- function(G, labels, lambda = 1, iters = 3L, sig_threshold = 3, fixed_labels_ = NULL, thread_no = 0L) {
    .Call(`_actionet_C_runLPA`, G, labels, lambda, iters, sig_threshold, fixed_labels_, thread_no)
}

#' Computes network diffusion over a given network, starting with an arbitrarty
#' set of initial scores
#'
#' @param G Input graph
#' @param X0 Matrix of initial values per diffusion (ncol(G) == nrow(G) == ncol(X0))
#' @param thread_no Number of parallel threads (default=0)
#' @param alpha Random-walk depth ( between [0, 1] ) ' @param max_it PageRank iterations
#'
#' @return Matrix of diffusion scores
#'
#' @examples
#' G = colNets(ace)$ACTIONet
#' gene.expression = Matrix::t(logcounts(ace))[c("CD19", "CD14", "CD16"), ]
#' smoothed.expression = computeNetworkDiffusionApprox(G, gene.expression)
C_computeNetworkDiffusion <- function(G, X0, alpha = 0.85, max_it = 5L, thread_no = 0L, approx = FALSE, norm_method = 0L, tol = 1e-8) {
    .Call(`_actionet_C_computeNetworkDiffusion`, G, X0, alpha, max_it, thread_no, approx, norm_method, tol)
}

#' Compute coreness of graph vertices
#'
#' @param G Input graph
#'
#' @return cn core-number of each graph node
#'
#' @examples
#' G = colNets(ace)$ACTIONet
#' cn = computeCoreness(G)
C_computeCoreness <- function(G) {
    .Call(`_actionet_C_computeCoreness`, G)
}

#' Compute coreness of subgraph vertices induced by each archetype
#'
#' @param G Input graph
#' @param sample_assignments Archetype discretization (output of mergeArchetypes())
#'
#' @return cn core-number of each graph node
#'
#' @examples
#' G = colNets(ace)$ACTIONet
#' assignments = ace$archetype.assignment
#' connectivity = computeCoreness(G, assignments)
C_computeArchetypeCentrality <- function(G, sample_assignments) {
    .Call(`_actionet_C_computeArchetypeCentrality`, G, sample_assignments)
}

C_autocorrelation_Moran_parametric <- function(G, scores, normalization_method = 4L, thread_no = 0L) {
    .Call(`_actionet_C_autocorrelation_Moran_parametric`, G, scores, normalization_method, thread_no)
}

C_autocorrelation_Moran <- function(G, scores, normalization_method = 1L, perm_no = 30L, thread_no = 0L) {
    .Call(`_actionet_C_autocorrelation_Moran`, G, scores, normalization_method, perm_no, thread_no)
}

C_autocorrelation_Geary <- function(G, scores, normalization_method = 1L, perm_no = 30L, thread_no = 0L) {
    .Call(`_actionet_C_autocorrelation_Geary`, G, scores, normalization_method, perm_no, thread_no)
}

C_computeGraphLabelEnrichment <- function(G, scores, thread_no = 0L) {
    .Call(`_actionet_C_computeGraphLabelEnrichment`, G, scores, thread_no)
}

#' Computes feature enrichment wrt a given annotation
#'
#' @param scores Specificity scores of features
#' @param associations Binary matrix of annotations
#' @param L Length of the top-ranked scores to scan
#'
#' @return Matrix of log-pvalues
#'
#' @examples
#' data("gProfilerDB_human")
#' G = colNets(ace)$ACTIONet
#' associations = gProfilerDB_human$SYMBOL$REAC
#' common.genes = intersect(rownames(ace), rownames(associations))
#' specificity_scores = rowFactors(ace)[["H_merged_upper_significance"]]
#' logPvals = computeFeatureSpecificity(
#' specificity_scores[common.genes, ], annotations[common.genes, ]
#' )
#' rownames(logPvals) = colnames(specificity_scores)
#' colnames(logPvals) = colnames(annotations)
C_assess_enrichment <- function(scores, associations, thread_no = 0L) {
    .Call(`_actionet_C_assess_enrichment`, scores, associations, thread_no)
}

#' Aggregate matrix within groups (rowwise or columnwise)
#'
#' @param S matrix of type "dMatrix"
#' @param sample_assignments Vector of groupings. Group labels must be continuous integers or coercible to such.
#' @param axis 0 for rowwise (default), 1 for columnwise
#' @return Aggregated matrix
#'
C_computeGroupedSumsSparse <- function(S, sample_assignments, axis = 0L) {
    .Call(`_actionet_C_computeGroupedSumsSparse`, S, sample_assignments, axis)
}

C_computeGroupedSumsSparse2 <- function(S, sample_assignments, axis = 0L) {
    .Call(`_actionet_C_computeGroupedSumsSparse2`, S, sample_assignments, axis)
}

C_computeGroupedSumsDense <- function(S, sample_assignments, axis = 0L) {
    .Call(`_actionet_C_computeGroupedSumsDense`, S, sample_assignments, axis)
}

#' Average matrix within groups (rowwise or columnwise)
#'
#' @param S matrix
#' @param sample_assignments Vector of groupings. Group labels must be continuous integers or coercible to such.
#' @param axis 0 for rowwise (default), 1 for columnwise
#' @return Averaged matrix
#'
C_computeGroupedMeansSparse <- function(S, sample_assignments, axis = 0L) {
    .Call(`_actionet_C_computeGroupedMeansSparse`, S, sample_assignments, axis)
}

C_computeGroupedMeansSparse2 <- function(S, sample_assignments, axis = 0L) {
    .Call(`_actionet_C_computeGroupedMeansSparse2`, S, sample_assignments, axis)
}

C_computeGroupedMeansDense <- function(S, sample_assignments, axis = 0L) {
    .Call(`_actionet_C_computeGroupedMeansDense`, S, sample_assignments, axis)
}

#' Variance matrix within groups (rowwise or columnwise)
#'
#' @param S matrix
#' @param sample_assignments Vector of groupings. Group labels must be continuous integers or coercible to such.
#' @param axis 0 for rowwise (default), 1 for columnwise
#' @return Variance matrix
#'
C_computeGroupedVarsSparse <- function(S, sample_assignments, axis = 0L) {
    .Call(`_actionet_C_computeGroupedVarsSparse`, S, sample_assignments, axis)
}

C_computeGroupedVarsSparse2 <- function(S, sample_assignments, axis = 0L) {
    .Call(`_actionet_C_computeGroupedVarsSparse2`, S, sample_assignments, axis)
}

C_computeGroupedVarsDense <- function(S, sample_assignments, axis = 0L) {
    .Call(`_actionet_C_computeGroupedVarsDense`, S, sample_assignments, axis)
}

C_normalizeMatrixSparse <- function(X, p = 1L, dim = 0L) {
    .Call(`_actionet_C_normalizeMatrixSparse`, X, p, dim)
}

C_normalizeMatrixDense <- function(X, p = 1L, dim = 0L) {
    .Call(`_actionet_C_normalizeMatrixDense`, X, p, dim)
}

C_scaleMatrixDense <- function(X, v, dim = 0L) {
    .Call(`_actionet_C_scaleMatrixDense`, X, v, dim)
}

C_scaleMatrixSparse <- function(X, v, dim = 0L) {
    .Call(`_actionet_C_scaleMatrixSparse`, X, v, dim)
}

C_normalizeGraph <- function(G, norm_method = 0L) {
    .Call(`_actionet_C_normalizeGraph`, G, norm_method)
}

#' Computes the maximum-weight bipartite graph matching
#'
#' @param G Adjacency matrix of the input graph
#'
#' @return G_matched An adjacency matrix with a maximum of one nonzero entry on
#' rows/columns
#'
#' @examples
#' G_matched = MWM_hungarian(G)
C_MWM_hungarian <- function(G) {
    .Call(`_actionet_C_MWM_hungarian`, G)
}

C_MWM_rank1 <- function(u, v, u_threshold = 0, v_threshold = 0) {
    .Call(`_actionet_C_MWM_rank1`, u, v, u_threshold, v_threshold)
}

C_xicor <- function(xvec, yvec, compute_pval = TRUE, seed = 0L) {
    .Call(`_actionet_C_xicor`, xvec, yvec, compute_pval, seed)
}

C_XICOR <- function(X, Y, compute_pval = TRUE, seed = 0L, thread_no = 0L) {
    .Call(`_actionet_C_XICOR`, X, Y, compute_pval, seed, thread_no)
}

C_layoutNetwork <- function(G, initial_coordinates, method = "umap", n_components = 2L, spread = 1, min_dist = 1, n_epochs = 0L, learning_rate = 1, repulsion_strength = 1, negative_sample_rate = 5, approx_pow = FALSE, pcg_rand = TRUE, batch = TRUE, grain_size = 1L, seed = 0L, thread_no = 0L, verbose = TRUE, a = 0, b = 0, opt_method = "adam", alpha = -1, beta1 = 0.5, beta2 = 0.9, eps = 1e-7) {
    .Call(`_actionet_C_layoutNetwork`, G, initial_coordinates, method, n_components, spread, min_dist, n_epochs, learning_rate, repulsion_strength, negative_sample_rate, approx_pow, pcg_rand, batch, grain_size, seed, thread_no, verbose, a, b, opt_method, alpha, beta1, beta2, eps)
}

C_computeNodeColors <- function(coordinates, thread_no = 1L) {
    .Call(`_actionet_C_computeNodeColors`, coordinates, thread_no)
}

