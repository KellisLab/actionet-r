# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Runs archetypal analysis (AA)
#'
#' @param A Input matrix.
#' @param W0 Matrix with <em>k</em> columns representing initial archetypes.
#' @param max_it Maximum number of iterations.
#' @param tol Convergence tolerance.
#'
#' @return Field with matrices <b>C</b> (<b>A.n_cols</b> x <em>k</em>) and <b>H</b> (<em>k</em> x <b>A.n_cols</b>).
#'
#' @examples
#' S_r = t(reducedDims(ace)$ACTION)
#' SPA.out = run_SPA(S_r, 10)
#' W0 = S_r[, SPA.selected_cols]
#' AA.out = run_AA(S_r, W0)
#' H = AA.out$H
#' cell.assignments = apply(H, 2, which.max)
run_AA <- function(A, W0, max_it = 100L, tol = 1e-6) {
    .Call(`_actionet_run_AA`, A, W0, max_it, tol)
}

#' Run ACTION decomposition algorithm
#'
#' @param S_r Input matrix. Usually a reduced representation of the raw data.
#' @param k_min Minimum number of archetypes (>= 2) to search for, and the beginning of the search range.
#' @param k_max Maximum number of archetypes (<= <b>S_r.n_cols</b>) to search for, and the end of the search range.
#' @param normalization Normalization method to apply on <b>S_r</b> before running ACTION.
#' @param max_it Maximum number of iterations for <code>run_AA()</code>.
#' @param tol Convergence tolerance for <code>run_AA()</code>.
#' @param thread_no Number of CPU threads to use. If 0, number is automatically determined.
#'
#' @return A named list with entries 'C' and 'H', each a list for different values of k
#'
#' @examples
#' ACTION.out = run_ACTION(S_r, k_max = 10)
#' H8 = ACTION.out$H[[8]]
#' cell.assignments = apply(H8, 2, which.max)
run_ACTION <- function(S_r, k_min = 2L, k_max = 30L, normalization = 1L, max_it = 100L, tol = 1e-6, thread_no = 0L) {
    .Call(`_actionet_run_ACTION`, S_r, k_min, k_max, normalization, max_it, tol, thread_no)
}

#' Filter and aggregate multi-level archetypes
#'
#' @param C_trace Field containing C matrices. Output of <code>run_ACTION()</code> in <code>ResACTION["C"]</code>.
#' @param H_trace Field containing H matrices. Output of <code>run_ACTION()</code> in <code>ResACTION["H"]</code>.
#' @param spec_th Minimum threshold (as z-score) to filter archetypes by specificity.
#' @param min_obs Minimum number of observations assigned to an archetypes needed to retain that archetype.
#'
#' @return A named list: \itemize{
#' \item selected_archs: List of final archetypes that passed the
#' filtering/pruning step.
#' \item C_stacked,H_stacked: Horizontal/Vertical
#' concatenation of filtered C and H matrices, respectively.
#' }
#'
#' @examples
#' S = logcounts(sce)
#' reduction.out = reduce(S, reduced_dim = 50)
#' S_r = reduction.out$S_r
#' ACTION.out = run_ACTION(S_r, k_max = 10)
#' reconstruction.out = reconstruct_archetypes(S, ACTION.out$C, ACTION.out$H)
collect_archetypes <- function(C_trace, H_trace, spec_th = -3, min_obs = 3L) {
    .Call(`_actionet_collect_archetypes`, C_trace, H_trace, spec_th, min_obs)
}

#' Identify and merge redundant archetypes into a representative subset
#'
#' @param S_r Reduced data matrix from which archetypes were found.
#' @param C_stacked Concatenated (and filtered) <code>C</code> (<b>S_r.n</b> x <em>n</em>) matrix.
#' Output of <code>collect_archetypes()</code> in <code>ResCollectArch["C_stacked"]</code>.
#' @param H_stacked Concatenated (and filtered) <code>H</code> (<b>S_r.n</b> x <em>n</em>) matrix.
#' Output of <code>collect_archetypes()</code> in <code>ResCollectArch["H_stacked"]</code>.
#' @param normalization Normalization method to apply to <b>S_r</b>.
#' @param thread_no Number of CPU threads to use. If 0, number is automatically determined.
#'
#' @return A named list: \itemize{
#' \item archetype_groups: Equivalent classes of archetypes (non-redundant)
#' \item C_merged,H_merged: C and H matrices of merged archetypes
#' \item sample_assignments: Assignment of samples/cells to merged archetypes
#' }
#' @examples
#' prune.out = collect_archetypes(ACTION.out$C, ACTION.out$H)
#'	G = buildNetwork(prune.out$H_stacked)
#' unification.out = merge_archetypes(G, S_r, prune.out$C_stacked, prune.out$H_stacked)
#' cell.clusters = unification.out$sample_assignments
merge_archetypes <- function(S_r, C_stacked, H_stacked, normalization = 0L, thread_no = 0L) {
    .Call(`_actionet_merge_archetypes`, S_r, C_stacked, H_stacked, normalization, thread_no)
}

#' Compute reduced kernel matrix
#'
#' @param S Input matrix (<em>vars</em> x <em>obs</em>).
#' May be <code>arma::mat</code> or <code>arma::sp_mat</code>.
#' @param dim Number of singular vectors to estimate. Passed to <code>runSVD()</code>.
#' @param svd_alg Singular value decomposition algorithm. See to <code>runSVD()</code> for options.
#' @param max_it Maximum number of iterations. Passed to <code>runSVD()</code>.
#' @param seed Random seed.
#' @param verbose Print status messages.
#'
#' @return Field with 5 elements:
#' - 0: <code>arma::mat</code> Reduced kernel matrix.
#' - 1: <code>arma::vec</code> Singular values.
#' - 2: <code>arma::mat</code> Left singular vectors.
#' - 3: <code>arma::mat</code> <b>A</b> perturbation matrix.
#' - 4: <code>arma::mat</code> <b>B</b> perturbation matrix.
#'
#' @examples
#' S = logcounts(sce)
#' reduction.out = reduce(S, reduced_dim = 50)
#' S_r = reduction.out$S_r
reduce_kernel <- function(S, reduced_dim = 50L, iter = 5L, seed = 0L, SVD_algorithm = 0L, verbose = 1L) {
    .Call(`_actionet_reduce_kernel`, S, reduced_dim, iter, seed, SVD_algorithm, verbose)
}

reduce_kernel_full <- function(S, reduced_dim = 50L, iter = 5L, seed = 0L, SVD_algorithm = 0L, verbose = 1L) {
    .Call(`_actionet_reduce_kernel_full`, S, reduced_dim, iter, seed, SVD_algorithm, verbose)
}

#' Solves min_{X} (|| AX - B ||) s.t. simplex constraint
#'
#' @param A Input matrix <em>A</em> in <em>AX - B</em>.
#' @param B Inout matrix <em>B</em> in <em>AX - B</em>.
#' @param computeXtX Return <em>Xt(X)</em>
#'
#' @return X Solution
#'
#' @examples
#' C = ACTION.out$C[[10]]
#' A = S_r %*% C
#' B = S_r
#' H = run_simplex_regression(A, B)
run_simplex_regression <- function(A, B, computeXtX = FALSE) {
    .Call(`_actionet_run_simplex_regression`, A, B, computeXtX)
}

#' Run successive projections algorithm (SPA) to solve separable NMF
#'
#' @param A Input matrix.
#' @param k Number of candidate vertices to solve for.
#'
#' @return A named list with entries 'selected_cols' and 'norms'
#' @examples
#' H = run_SPA(S_r, 10)
run_SPA <- function(A, k) {
    .Call(`_actionet_run_SPA`, A, k)
}

compute_marker_aggregate_stats <- function(G, S, marker_mat, alpha = 0.85, max_it = 5L, thread_no = 0L, ignore_baseline_expression = FALSE) {
    .Call(`_actionet_compute_marker_aggregate_stats`, G, S, marker_mat, alpha, max_it, thread_no, ignore_baseline_expression)
}

aggregate_genesets_vision <- function(G, S, marker_mat, norm_type = 2L, alpha = 0.85, max_it = 5L, tol = 1E-8, thread_no = 0L) {
    .Call(`_actionet_aggregate_genesets_vision`, G, S, marker_mat, norm_type, alpha, max_it, tol, thread_no)
}

#' Compute feature specificity (from archetype footprints)
#'
#' @param S Input matrix (sparseMatrix)
#' @param H A soft membership matrix - Typically H_merged from the merge_archetypes() function.
#'
#' @return A list with the over/under-logPvals
#'
#' @examples
#' prune.out = collect_archetypes(ACTION.out$C, ACTION.out$H)
#'	G = buildNetwork(prune.out$H_stacked)
#' unification.out = merge_archetypes(G, S_r, prune.out$C_stacked, prune.out$H_stacked)
#' cell.clusters = unification.out$sample_assignments
#' S.norm = renormalize_input_matrix(S, cell.clusters)
#' logPvals.list = compute_archetype_feature_specificity(S.norm, unification.out$H_merged)
#' specificity.scores = logPvals.list$upper_significance
compute_archetype_feature_specificity <- function(S, H, thread_no = 0L) {
    .Call(`_actionet_compute_archetype_feature_specificity`, S, H, thread_no)
}

compute_archetype_feature_specificity_full <- function(S, H, thread_no = 0L) {
    .Call(`_actionet_compute_archetype_feature_specificity_full`, S, H, thread_no)
}

#' Compute feature specificity (from cluster assignments)
#'
#' @param S Input matrix ("sparseMatrix")
#' @param sample_assignments Vector of cluster assignments
#'
#' @return A list with the over/under-logPvals
#'
#' @examples
#' prune.out = collect_archetypes(ACTION.out$C, ACTION.out$H)
#'	G = buildNetwork(prune.out$H_stacked)
#' unification.out = merge_archetypes(G, S_r, prune.out$C_stacked, prune.out$H_stacked)
#' cell.clusters = unification.out$sample_assignments
#' S.norm = renormalize_input_matrix(S, cell.clusters)
#' logPvals.list = compute_cluster_feature_specificity(S.norm, cell.clusters)
#' specificity.scores = logPvals.list$upper_significance
compute_cluster_feature_specificity <- function(S, sample_assignments, thread_no = 0L) {
    .Call(`_actionet_compute_cluster_feature_specificity`, S, sample_assignments, thread_no)
}

compute_cluster_feature_specificity_full <- function(S, sample_assignments, thread_no = 0L) {
    .Call(`_actionet_compute_cluster_feature_specificity_full`, S, sample_assignments, thread_no)
}

orthogonalize_batch_effect <- function(S, old_S_r, old_V, old_A, old_B, old_sigma, design) {
    .Call(`_actionet_orthogonalize_batch_effect`, S, old_S_r, old_V, old_A, old_B, old_sigma, design)
}

orthogonalize_batch_effect_full <- function(S, old_S_r, old_V, old_A, old_B, old_sigma, design) {
    .Call(`_actionet_orthogonalize_batch_effect_full`, S, old_S_r, old_V, old_A, old_B, old_sigma, design)
}

orthogonalize_basal <- function(S, old_S_r, old_V, old_A, old_B, old_sigma, basal) {
    .Call(`_actionet_orthogonalize_basal`, S, old_S_r, old_V, old_A, old_B, old_sigma, basal)
}

orthogonalize_basal_full <- function(S, old_S_r, old_V, old_A, old_B, old_sigma, basal) {
    .Call(`_actionet_orthogonalize_basal_full`, S, old_S_r, old_V, old_A, old_B, old_sigma, basal)
}

#' Computes SVD decomposition
#'
#' This is direct implementation of the randomized SVD algorithm:
#' From: IRLBA R Package
#'
#' @param A Input matrix ("sparseMatrix")
#' @param k Dimension of SVD decomposition
#' @param max_it Number of iterations (default=5)
#' @param seed Random seed (default=0)
#' @param algorithm SVD algorithm to use. Currently supported methods are blah blah blah
#'
#' @return A named list with U, sigma, and V components
#'
#' @examples
#' A = randn(100, 20)
#' svd.out = runSVD(A, dim = 3)
#' U = svd.out$u
runSVD <- function(A, k = 30L, max_it = 0L, seed = 0L, algorithm = 0L, verbose = 1L) {
    .Call(`_actionet_runSVD`, A, k, max_it, seed, algorithm, verbose)
}

runSVD_full <- function(A, k = 30L, max_it = 0L, seed = 0L, algorithm = 0L, verbose = 1L) {
    .Call(`_actionet_runSVD_full`, A, k, max_it, seed, algorithm, verbose)
}

perturbedSVD <- function(u, d, v, A, B) {
    .Call(`_actionet_perturbedSVD`, u, d, v, A, B)
}

computeNodeColors <- function(coordinates, thread_no) {
    .Call(`_actionet_computeNodeColors`, coordinates, thread_no)
}

#' Builds an interaction network from the multi-level archetypal decompositions
#'
#' @param H_stacked Output of the collect_archetypes() function.
#' @param density Overall density of constructed graph. The higher the density,
#' the more edges are retained (default = 1.0).
#' @param thread_no Number of parallel threads (default = 0).
#' @param mutual_edges_only Symmetrization strategy for nearest-neighbor edges.
#' If it is true, only mutual nearest-neighbors are returned (default=TRUE).
#'
#' @return G Adjacency matrix of the ACTIONet graph.
#'
#' @examples
#' prune.out = collect_archetypes(ACTION.out$C, ACTION.out$H)
#'	G = buildNetwork(prune.out$H_stacked)
buildNetwork <- function(H, algorithm = "k*nn", distance_metric = "jsd", density = 1.0, thread_no = 0L, mutual_edges_only = TRUE, k = 10L) {
    .Call(`_actionet_buildNetwork`, H, algorithm, distance_metric, density, thread_no, mutual_edges_only, k)
}

run_LPA <- function(G, labels, lambda = 1, iters = 3L, sig_threshold = 3, fixed_labels_ = NULL, thread_no = 0L) {
    .Call(`_actionet_run_LPA`, G, labels, lambda, iters, sig_threshold, fixed_labels_, thread_no)
}

#' Computes network diffusion over a given network, starting with an arbitrarty
#' set of initial scores
#'
#' @param G Input graph
#' @param X0 Matrix of initial values per diffusion (ncol(G) == nrow(G) == ncol(X0))
#' @param thread_no Number of parallel threads (default=0)
#' @param alpha Random-walk depth ( between [0, 1] )
#' @param max_it PageRank iterations
#'
#' @return Matrix of diffusion scores
#'
#' @examples
#' G = colNets(ace)$ACTIONet
#' gene.expression = Matrix::t(logcounts(ace))[c("CD19", "CD14", "CD16"), ]
#' smoothed.expression = compute_network_diffusion(G, gene.expression)
compute_network_diffusion_fast <- function(G, X0, alpha = 0.85, max_it = 3L, thread_no = 0L) {
    .Call(`_actionet_compute_network_diffusion_fast`, G, X0, alpha, max_it, thread_no)
}

#' Computes network diffusion over a given network, starting with an arbitrarty
#' set of initial scores
#'
#' @param G Input graph
#' @param X0 Matrix of initial values per diffusion (ncol(G) == nrow(G) == ncol(X0))
#' @param thread_no Number of parallel threads (default=0)
#' @param alpha Random-walk depth ( between [0, 1] ) ' @param max_it PageRank iterations
#'
#' @return Matrix of diffusion scores
#'
#' @examples
#' G = colNets(ace)$ACTIONet
#' gene.expression = Matrix::t(logcounts(ace))[c("CD19", "CD14", "CD16"), ]
#' smoothed.expression = compute_network_diffusion_approx(G, gene.expression)
compute_network_diffusion_approx <- function(G, X0, norm_type = 0L, alpha = 0.85, max_it = 5L, tol = 1e-8, thread_no = 0L) {
    .Call(`_actionet_compute_network_diffusion_approx`, G, X0, norm_type, alpha, max_it, tol, thread_no)
}

#' Compute coreness of graph vertices
#'
#' @param G Input graph
#'
#' @return cn core-number of each graph node
#'
#' @examples
#' G = colNets(ace)$ACTIONet
#' cn = compute_core_number(G)
compute_core_number <- function(G) {
    .Call(`_actionet_compute_core_number`, G)
}

#' Compute coreness of subgraph vertices induced by each archetype
#'
#' @param G Input graph
#' @param sample_assignments Archetype discretization (output of merge_archetypes())
#'
#' @return cn core-number of each graph node
#'
#' @examples
#' G = colNets(ace)$ACTIONet
#' assignments = ace$archetype.assignment
#' connectivity = compute_core_number(G, assignments)
compute_archetype_core_centrality <- function(G, sample_assignments) {
    .Call(`_actionet_compute_archetype_core_centrality`, G, sample_assignments)
}

autocorrelation_Moran_parametric <- function(G, scores, normalization_method = 4L, thread_no = 0L) {
    .Call(`_actionet_autocorrelation_Moran_parametric`, G, scores, normalization_method, thread_no)
}

autocorrelation_Moran <- function(G, scores, normalization_method = 1L, perm_no = 30L, thread_no = 0L) {
    .Call(`_actionet_autocorrelation_Moran`, G, scores, normalization_method, perm_no, thread_no)
}

autocorrelation_Geary <- function(G, scores, normalization_method = 1L, perm_no = 30L, thread_no = 0L) {
    .Call(`_actionet_autocorrelation_Geary`, G, scores, normalization_method, perm_no, thread_no)
}

assess_label_enrichment <- function(G, M, thread_no = 0L) {
    .Call(`_actionet_assess_label_enrichment`, G, M, thread_no)
}

#' Computes feature enrichment wrt a given annotation
#'
#' @param scores Specificity scores of features
#' @param associations Binary matrix of annotations
#' @param L Length of the top-ranked scores to scan
#'
#' @return Matrix of log-pvalues
#'
#' @examples
#' data("gProfilerDB_human")
#' G = colNets(ace)$ACTIONet
#' associations = gProfilerDB_human$SYMBOL$REAC
#' common.genes = intersect(rownames(ace), rownames(associations))
#' specificity_scores = rowFactors(ace)[["H_merged_upper_significance"]]
#' logPvals = compute_feature_specificity(
#' specificity_scores[common.genes, ], annotations[common.genes, ]
#' )
#' rownames(logPvals) = colnames(specificity_scores)
#' colnames(logPvals) = colnames(annotations)
assess_enrichment <- function(scores, associations, thread_no = 0L) {
    .Call(`_actionet_assess_enrichment`, scores, associations, thread_no)
}

#' Aggregate matrix within groups
#'
#' @param S matrix of type "dMatrix"
#' @param sample_assignments Vector of column groupings. Group labels must be continuous integers or coercible to such.
#'
#' @return S matrix with columns of values aggregated within each group of sample_assignments
#'
compute_grouped_rowsums <- function(S, sample_assignments) {
    .Call(`_actionet_compute_grouped_rowsums`, S, sample_assignments)
}

compute_grouped_rowsums_full <- function(S, sample_assignments) {
    .Call(`_actionet_compute_grouped_rowsums_full`, S, sample_assignments)
}

#' Average matrix within groups
#'
#' @param S matrix
#' @param sample_assignments Vector of column groupings. Group labels must be continuous integers or coercible to such.
#'
#' @return S matrix with columns of values average within each group of sample_assignments
#'
compute_grouped_rowmeans <- function(S, sample_assignments) {
    .Call(`_actionet_compute_grouped_rowmeans`, S, sample_assignments)
}

compute_grouped_rowmeans_full <- function(S, sample_assignments) {
    .Call(`_actionet_compute_grouped_rowmeans_full`, S, sample_assignments)
}

compute_grouped_rowvars <- function(S, sample_assignments) {
    .Call(`_actionet_compute_grouped_rowvars`, S, sample_assignments)
}

compute_grouped_rowvars_full <- function(S, sample_assignments) {
    .Call(`_actionet_compute_grouped_rowvars_full`, S, sample_assignments)
}

#' Computes the maximum-weight bipartite graph matching
#'
#' @param G Adjacency matrix of the input graph
#'
#' @return G_matched An adjacency matrix with a maximum of one nonzero entry on
#' rows/columns
#'
#' @examples
#' G_matched = MWM_hungarian(G)
MWM_hungarian <- function(G) {
    .Call(`_actionet_MWM_hungarian`, G)
}

MWM_rank1 <- function(u, v, u_threshold = 0, v_threshold = 0) {
    .Call(`_actionet_MWM_rank1`, u, v, u_threshold, v_threshold)
}

normalize_mat <- function(X, p = 0L, dim = 0L) {
    .Call(`_actionet_normalize_mat`, X, p, dim)
}

normalize_spmat <- function(X, p = 0L, dim = 0L) {
    .Call(`_actionet_normalize_spmat`, X, p, dim)
}

xicor <- function(xvec, yvec, compute_pval = TRUE, seed = 0L) {
    .Call(`_actionet_xicor`, xvec, yvec, compute_pval, seed)
}

XICOR <- function(X, Y, compute_pval = TRUE, seed = 0L, thread_no = 0L) {
    .Call(`_actionet_XICOR`, X, Y, compute_pval, seed, thread_no)
}

layoutNetwork <- function(G, initial_coordinates, method = "umap", n_components = 2L, spread = 1, min_dist = 1, n_epochs = 0L, learning_rate = 1, repulsion_strength = 1, negative_sample_rate = 5, approx_pow = FALSE, pcg_rand = TRUE, batch = TRUE, grain_size = 1L, seed = 0L, thread_no = 0L, verbose = TRUE, a = 0, b = 0, opt_method = "adam", alpha = -1, beta1 = 0.5, beta2 = 0.9, eps = 1e-7) {
    .Call(`_actionet_layoutNetwork`, G, initial_coordinates, method, n_components, spread, min_dist, n_epochs, learning_rate, repulsion_strength, negative_sample_rate, approx_pow, pcg_rand, batch, grain_size, seed, thread_no, verbose, a, b, opt_method, alpha, beta1, beta2, eps)
}

# Register entry points for exported C++ functions
methods::setLoadAction(function(ns) {
    .Call(`_actionet_RcppExport_registerCCallable`)
})
