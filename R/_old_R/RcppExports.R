# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Set the RNG Seed from within Rcpp
#'
#' Within Rcpp, one can set the R session seed without triggering
#' the CRAN rng modifier check.
#' @param seed A \code{double} that is the seed one wishes to use.
#' @return A set RNG scope.
#' @examples
#' set.seed(10)
#' x = rnorm(5,0,1)
#' set_seed(10)
#' y = rnorm(5,0,1)
#' all.equal(x,y, check.attributes = F)
set_seed <- function(seed) {
    invisible(.Call(`_ACTIONet_set_seed`, seed))
}

#' Computes SVD decomposition
#'
#' This is direct implementation of the randomized SVD algorithm:
#' From: IRLBA R Package
#'
#' @param A Input matrix ("sparseMatrix")
#' @param k Dimension of SVD decomposition
#' @param max_it Number of iterations (default=5)
#' @param seed Random seed (default=0)
#' @param algorithm SVD algorithm to use. Currently supported methods are blah blah blah
#'
#' @return A named list with U, sigma, and V components
#'
#' @examples
#' A = randn(100, 20)
#' svd.out = runSVD(A, dim = 3)
#' U = svd.out$u
runSVD <- function(A, k = 30L, max_it = 0L, seed = 0L, algorithm = 0L, verbose = 1L) {
    .Call(`_ACTIONet_runSVD`, A, k, max_it, seed, algorithm, verbose)
}

runSVD_full <- function(A, k = 30L, max_it = 0L, seed = 0L, algorithm = 0L, verbose = 1L) {
    .Call(`_ACTIONet_runSVD_full`, A, k, max_it, seed, algorithm, verbose)
}

perturbedSVD <- function(u, d, v, A, B) {
    .Call(`_ACTIONet_perturbedSVD`, u, d, v, A, B)
}

orthogonalize_batch_effect <- function(S, old_S_r, old_V, old_A, old_B, old_sigma, design) {
    .Call(`_ACTIONet_orthogonalize_batch_effect`, S, old_S_r, old_V, old_A, old_B, old_sigma, design)
}

orthogonalize_batch_effect_full <- function(S, old_S_r, old_V, old_A, old_B, old_sigma, design) {
    .Call(`_ACTIONet_orthogonalize_batch_effect_full`, S, old_S_r, old_V, old_A, old_B, old_sigma, design)
}

orthogonalize_basal <- function(S, old_S_r, old_V, old_A, old_B, old_sigma, basal) {
    .Call(`_ACTIONet_orthogonalize_basal`, S, old_S_r, old_V, old_A, old_B, old_sigma, basal)
}

orthogonalize_basal_full <- function(S, old_S_r, old_V, old_A, old_B, old_sigma, basal) {
    .Call(`_ACTIONet_orthogonalize_basal_full`, S, old_S_r, old_V, old_A, old_B, old_sigma, basal)
}

#' Computes reduced kernel matrix for a given (single-cell) profile
#'
#' @param S Input matrix ("sparseMatrix")
#' @param reduced_dim Dimension of the reduced kernel matrix (default=50)
#' @param iters Number of SVD iterations (default=5)
#' @param seed Random seed (default=0)
#' @param reduction_algorithm Kernel reduction algorithm. Currently only ACTION
#' method (1) is implemented (default=1)
#' @param SVD_algorithm SVD algorithm to use. Currently supported methods
#' are Halko (1) and Feng (2) (default=1)
#'
#' @return A named list with S_r, V, lambda, and exp_var. \itemize{
#' \item S_r: reduced kernel matrix of size reduced_dim x #samples.
#' \item V: Associated left singular-vectors (useful for reconstructing
#' discriminative scores for features, such as genes).
#' \item lambda, exp_var: Summary statistics of the sigular-values.
#' }
#'
#' @examples
#' S = logcounts(sce)
#' reduction.out = reduce(S, reduced_dim = 50)
#' S_r = reduction.out$S_r
reduce_kernel <- function(S, reduced_dim = 50L, iter = 5L, seed = 0L, SVD_algorithm = 0L, prenormalize = FALSE, verbose = 1L) {
    .Call(`_ACTIONet_reduce_kernel`, S, reduced_dim, iter, seed, SVD_algorithm, prenormalize, verbose)
}

#' Computes reduced kernel matrix for a given (single-cell) profile
#'
#' @param S Input matrix ("matrix")
#' @param reduced_dim Dimension of the reduced kernel matrix (default=50)
#' @param iters Number of SVD iterations (default=5)
#' @param seed Random seed (default=0)
#' @param reduction_algorithm Kernel reduction algorithm. Currently only ACTION
#' method (1) is implemented (default=1)
#' @param SVD_algorithm SVD algorithm to use. Currently supported methods are
#' Halko (1) and Feng (2) (default=1)
#'
#' @return A named list with S_r, V, lambda, and exp_var. \itemize{
#' \item S_r: reduced kernel matrix of size reduced_dim x #samples.
#' \item V: Associated left singular-vectors (useful for reconstructing
#' discriminative scores for features, such as genes).
#' \item lambda, exp_var: Summary statistics of the sigular-values.
#' }
#'
#' @examples
#' S = logcounts(sce)
#' reduction.out = reduce(S, reduced_dim = 50)
#' S_r = reduction.out$S_r
reduce_kernel_full <- function(S, reduced_dim = 50L, iter = 5L, seed = 0L, SVD_algorithm = 0L, prenormalize = FALSE, verbose = 1L) {
    .Call(`_ACTIONet_reduce_kernel_full`, S, reduced_dim, iter, seed, SVD_algorithm, prenormalize, verbose)
}

#' Solves min_{X} (|| AX - B ||) s.t. simplex constraint
#'
#' @param A Input matrix
#' @param B Input matrix
#'
#' @return X Solution
#'
#' @examples
#' C = ACTION.out$C[[10]]
#' A = S_r %*% C
#' B = S_r
#' H = run_simplex_regression(A, B)
run_simplex_regression <- function(A, B, computeXtX = FALSE) {
    .Call(`_ACTIONet_run_simplex_regression`, A, B, computeXtX)
}

#' Runs Successive Projection Algorithm (SPA) to solve separable NMF
#'
#' @param A Input matrix
#' @param k Number of columns to select
#'
#' @return A named list with entries 'selected_columns' and 'norms'
#' @examples
#' H = run_SPA(S_r, 10)
run_SPA <- function(A, k) {
    .Call(`_ACTIONet_run_SPA`, A, k)
}

#' Runs multi-level ACTION decomposition method
#'
#' @param S_r Reduced kernel matrix
#' @param k_min Minimum number of archetypes to consider (default=2)
#' @param k_max Maximum number of archetypes to consider, or "depth" of
#' decomposition (default=30)
#' @param thread_no Number of parallel threads (default = 0)
#' @param max_it,min_delta Convergence parameters for archetypal analysis
#'
#' @return A named list with entries 'C' and 'H', each a list for different
#' values of k ' @examples ' ACTION.out = run_ACTION(S_r, k_max = 10) ' H8 =
#' ACTION.out$H[[8]] ' cell.assignments = apply(H8, 2, which.max)
run_ACTION <- function(S_r, k_min = 2L, k_max = 30L, normalization = 1L, max_it = 100L, min_delta = 1e-6, thread_no = 0L) {
    .Call(`_ACTIONet_run_ACTION`, S_r, k_min, k_max, normalization, max_it, min_delta, thread_no)
}

#' Runs basic archetypal analysis
#'
#' @param A Inpu matrix
#' @param W0 Starting archetypes
#' @param max_it,min_delta Convergence parameters for archetypal analysis
#'
#' @return A named list with entries 'C' and 'H', each a list for different
#' values of k ' @examples ' S_r = t(reducedDims(ace)$ACTION) ' SPA.out =
#' run_SPA(S_r, 10) ' W0 = S_r[, SPA.out$selected_columns] ' AA.out =
#' run_AA(S_r, W0) ' H = AA.out$H ' cell.assignments = apply(H, 2, which.max)
run_AA <- function(A, W0, max_it = 100L, min_delta = 1e-6) {
    .Call(`_ACTIONet_run_AA`, A, W0, max_it, min_delta)
}

#' Filters multi-level archetypes and concatenate filtered archetypes.
#' (Pre-ACTIONet archetype processing)
#'
#' @param C_trace,H_trace Output of ACTION
#' @param min_specificity_z_threshold Defines the stringency of pruning
#' nonspecific archetypes. The larger the value, the more archetypes will be
#' filtered out (default=-1)
#'
#' @return A named list: \itemize{
#' \item selected_archs: List of final archetypes that passed the
#' filtering/pruning step.
#' \item C_stacked,H_stacked: Horizontal/Vertical
#' concatenation of filtered C and H matrices, respectively.
#' }
#'
#' @examples
#' S = logcounts(sce)
#' reduction.out = reduce(S, reduced_dim = 50)
#' S_r = reduction.out$S_r
#' ACTION.out = run_ACTION(S_r, k_max = 10)
#' reconstruction.out = reconstruct_archetypes(S, ACTION.out$C, ACTION.out$H)
prune_archetypes <- function(C_trace, H_trace, min_specificity_z_threshold = -3, min_cells = 3L) {
    .Call(`_ACTIONet_prune_archetypes`, C_trace, H_trace, min_specificity_z_threshold, min_cells)
}

#' Identifies and aggregates redundant archetypes into equivalent classes
#' (Post-ACTIONet archetype processing)
#'
#' @param G Adjacency matrix of the ACTIONet graph
#' @param S_r Reduced kernel profile
#' @param archetypes Archetype profile (S*C)
#' @param C_stacked,H_stacked Output of reconstruct_archetypes()
#' @param minPoints, minClusterSize, outlier_threshold HDBSCAN parameters
#' @param reduced_dim Kernel reduction
#'
#' @return A named list: \itemize{
#' \item archetype_groups: Equivalent classes of archetypes (non-redundant)
#' \item C_unified,H_unified: C and H matrices of unified archetypes
#' \item sample_assignments: Assignment of samples/cells to unified archetypes
#' }
#' @examples
#' prune.out = prune_archetypes(ACTION.out$C, ACTION.out$H)
#'	G = buildNetwork(prune.out$H_stacked)
#' unification.out = unify_archetypes(G, S_r, prune.out$C_stacked, prune.out$H_stacked)
#' cell.clusters = unification.out$sample_assignments
unify_archetypes <- function(S_r, C_stacked, H_stacked, normalization = 0L, thread_no = 0L) {
    .Call(`_ACTIONet_unify_archetypes`, S_r, C_stacked, H_stacked, normalization, thread_no)
}

#' Builds an interaction network from the multi-level archetypal decompositions
#'
#' @param H_stacked Output of the prune_archetypes() function.
#' @param density Overall density of constructed graph. The higher the density,
#' the more edges are retained (default = 1.0).
#' @param thread_no Number of parallel threads (default = 0).
#' @param mutual_edges_only Symmetrization strategy for nearest-neighbor edges.
#' If it is true, only mutual nearest-neighbors are returned (default=TRUE).
#'
#' @return G Adjacency matrix of the ACTIONet graph.
#'
#' @examples
#' prune.out = prune_archetypes(ACTION.out$C, ACTION.out$H)
#'	G = buildNetwork(prune.out$H_stacked)
buildNetwork <- function(H, algorithm = "k*nn", distance_metric = "jsd", density = 1.0, thread_no = 0L, mutual_edges_only = TRUE, k = 10L) {
    .Call(`_ACTIONet_buildNetwork`, H, algorithm, distance_metric, density, thread_no, mutual_edges_only, k)
}

#' Performs stochastic force-directed layout on the input graph (ACTIONet)
#'
#' @param G Adjacency matrix of the ACTIONet graph
#' @param S_r Reduced kernel matrix (is used for reproducible initialization).
#' @param compactness_level A value between 0-100, indicating the compactness
#' of ACTIONet layout (default=50)
#' @param n_epochs Number of epochs for SGD algorithm (default=100).
#' @param thread_no Number of threads (default = 0).
#'
#' @return A named list \itemize{
#' \item coordinates 2D coordinates of vertices.
#' \item coordinates_3D 3D coordinates of vertices.
#' \item colors De novo color of nodes inferred from their 3D embedding.
#' }
#'
#' @examples
#'	G = buildNetwork(prune.out$H_stacked)
#'	vis.out = layoutNetwrok(G, S_r)
layoutNetwork <- function(G, initial_position, method = "umap", presmooth_network = FALSE, min_dist = 1, spread = 1, gamma = 1.0, n_epochs = 500L, thread_no = 0L, seed = 0L, learning_rate = 1.0, sim2dist = 2L) {
    .Call(`_ACTIONet_layoutNetwork`, G, initial_position, method, presmooth_network, min_dist, spread, gamma, n_epochs, thread_no, seed, learning_rate, sim2dist)
}

#' Aggregate matrix within groups
#'
#' @param S matrix of type "dMatrix"
#' @param sample_assignments Vector of column groupings. Group labels must be continuous integers or coercible to such.
#'
#' @return S matrix with columns of values aggregated within each group of sample_assignments
#'
compute_grouped_rowsums <- function(S, sample_assignments) {
    .Call(`_ACTIONet_compute_grouped_rowsums`, S, sample_assignments)
}

#' Aggregate matrix within groups
#'
#' @param S matrix
#' @param sample_assignments Vector of column groupings. Group labels must be continuous integers or coercible to such.
#'
#' @return S matrix with columns of values aggregated within each group of sample_assignments
#'
compute_grouped_rowsums_full <- function(S, sample_assignments) {
    .Call(`_ACTIONet_compute_grouped_rowsums_full`, S, sample_assignments)
}

#' Average matrix within groups
#'
#' @param S matrix of type "dMatrix"
#' @param sample_assignments Vector of column groupings. Group labels must be continuous integers or coercible to such.
#'
#' @return S matrix with columns of values average within each group of sample_assignments
#'
compute_grouped_rowmeans <- function(S, sample_assignments) {
    .Call(`_ACTIONet_compute_grouped_rowmeans`, S, sample_assignments)
}

#' Average matrix within groups
#'
#' @param S matrix
#' @param sample_assignments Vector of column groupings. Group labels must be continuous integers or coercible to such.
#'
#' @return S matrix with columns of values average within each group of sample_assignments
#'
compute_grouped_rowmeans_full <- function(S, sample_assignments) {
    .Call(`_ACTIONet_compute_grouped_rowmeans_full`, S, sample_assignments)
}

compute_grouped_rowvars <- function(S, sample_assignments) {
    .Call(`_ACTIONet_compute_grouped_rowvars`, S, sample_assignments)
}

compute_grouped_rowvars_full <- function(S, sample_assignments) {
    .Call(`_ACTIONet_compute_grouped_rowvars_full`, S, sample_assignments)
}

#' Compute feature specificity (from archetype footprints)
#'
#' @param S Input matrix (sparseMatrix)
#' @param H A soft membership matrix - Typically H_unified from the unify_archetypes() function.
#'
#' @return A list with the over/under-logPvals
#'
#' @examples
#' prune.out = prune_archetypes(ACTION.out$C, ACTION.out$H)
#'	G = buildNetwork(prune.out$H_stacked)
#' unification.out = unify_archetypes(G, S_r, prune.out$C_stacked, prune.out$H_stacked)
#' cell.clusters = unification.out$sample_assignments
#' S.norm = renormalize_input_matrix(S, cell.clusters)
#' logPvals.list = compute_archetype_feature_specificity(S.norm, unification.out$H_unified)
#' specificity.scores = logPvals.list$upper_significance
compute_archetype_feature_specificity <- function(S, H, thread_no = 0L) {
    .Call(`_ACTIONet_compute_archetype_feature_specificity`, S, H, thread_no)
}

#' Compute feature specificity (from archetype footprints)
#'
#' @param S Input matrix ("matrix" type)
#' @param H A soft membership matrix - Typically H_unified from the unify_archetypes() function.
#'
#' @return A list with the over/under-logPvals
#'
#' @examples
#' prune.out = prune_archetypes(ACTION.out$C, ACTION.out$H)
#'	G = buildNetwork(prune.out$H_stacked)
#' unification.out = unify_archetypes(G, S_r, prune.out$C_stacked, prune.out$H_stacked)
#' cell.clusters = unification.out$sample_assignments
#' S.norm = renormalize_input_matrix(S, cell.clusters)
#' logPvals.list = compute_archetype_feature_specificity(S.norm, unification.out$H_unified)
#' specificity.scores = logPvals.list$upper_significance
compute_archetype_feature_specificity_full <- function(S, H, thread_no = 0L) {
    .Call(`_ACTIONet_compute_archetype_feature_specificity_full`, S, H, thread_no)
}

#' Compute feature specificity (from cluster assignments)
#'
#' @param S Input matrix ("sparseMatrix")
#' @param sample_assignments Vector of cluster assignments
#'
#' @return A list with the over/under-logPvals
#'
#' @examples
#' prune.out = prune_archetypes(ACTION.out$C, ACTION.out$H)
#'	G = buildNetwork(prune.out$H_stacked)
#' unification.out = unify_archetypes(G, S_r, prune.out$C_stacked, prune.out$H_stacked)
#' cell.clusters = unification.out$sample_assignments
#' S.norm = renormalize_input_matrix(S, cell.clusters)
#' logPvals.list = compute_cluster_feature_specificity(S.norm, cell.clusters)
#' specificity.scores = logPvals.list$upper_significance
compute_cluster_feature_specificity <- function(S, sample_assignments, thread_no = 0L) {
    .Call(`_ACTIONet_compute_cluster_feature_specificity`, S, sample_assignments, thread_no)
}

#' Compute feature specificity (from cluster assignments)
#'
#' @param S Input matrix ("matrix")
#' @param sample_assignments Vector of cluster assignments
#'
#' @return A list with the over/under-logPvals
#'
#' @examples
#' prune.out = prune_archetypes(ACTION.out$C, ACTION.out$H)
#'	G = buildNetwork(prune.out$H_stacked)
#' unification.out = unify_archetypes(G, S_r, prune.out$C_stacked, prune.out$H_stacked)
#' cell.clusters = unification.out$sample_assignments
#' S.norm = renormalize_input_matrix(S, cell.clusters)
#' logPvals.list = compute_cluster_feature_specificity(S.norm, cell.clusters)
#' specificity.scores = logPvals.list$upper_significance
compute_cluster_feature_specificity_full <- function(S, sample_assignments, thread_no = 0L) {
    .Call(`_ACTIONet_compute_cluster_feature_specificity_full`, S, sample_assignments, thread_no)
}

#' Compute coreness of graph vertices
#'
#' @param G Input graph
#'
#' @return cn core-number of each graph node
#'
#' @examples
#' G = colNets(ace)$ACTIONet
#' cn = compute_core_number(G)
compute_core_number <- function(G) {
    .Call(`_ACTIONet_compute_core_number`, G)
}

#' Compute coreness of subgraph vertices induced by each archetype
#'
#' @param G Input graph
#' @param sample_assignments Archetype discretization (output of unify_archetypes())
#'
#' @return cn core-number of each graph node
#'
#' @examples
#' G = colNets(ace)$ACTIONet
#' assignments = ace$archetype.assignment
#' connectivity = compute_core_number(G, assignments)
compute_archetype_core_centrality <- function(G, sample_assignments) {
    .Call(`_ACTIONet_compute_archetype_core_centrality`, G, sample_assignments)
}

#' Computes network diffusion over a given network, starting with an arbitrarty
#' set of initial scores
#'
#' @param G Input graph
#' @param X0 Matrix of initial values per diffusion (ncol(G) == nrow(G) == ncol(X0))
#' @param thread_no Number of parallel threads (default=0)
#' @param alpha Random-walk depth ( between [0, 1] )
#' @param max_it PageRank iterations
#'
#' @return Matrix of diffusion scores
#'
#' @examples
#' G = colNets(ace)$ACTIONet
#' gene.expression = Matrix::t(logcounts(ace))[c("CD19", "CD14", "CD16"), ]
#' smoothed.expression = compute_network_diffusion(G, gene.expression)
compute_network_diffusion_fast <- function(G, X0, thread_no = 0L, alpha = 0.85, max_it = 3L) {
    .Call(`_ACTIONet_compute_network_diffusion_fast`, G, X0, thread_no, alpha, max_it)
}

#' Computes feature enrichment wrt a given annotation
#'
#' @param scores Specificity scores of features
#' @param associations Binary matrix of annotations
#' @param L Length of the top-ranked scores to scan
#'
#' @return Matrix of log-pvalues
#'
#' @examples
#' data("gProfilerDB_human")
#' G = colNets(ace)$ACTIONet
#' associations = gProfilerDB_human$SYMBOL$REAC
#' common.genes = intersect(rownames(ace), rownames(associations))
#' specificity_scores = rowFactors(ace)[["H_unified_upper_significance"]]
#' logPvals = compute_feature_specificity(
#' specificity_scores[common.genes, ], annotations[common.genes, ]
#' )
#' rownames(logPvals) = colnames(specificity_scores)
#' colnames(logPvals) = colnames(annotations)
assess_enrichment <- function(scores, associations, thread_no = 0L) {
    .Call(`_ACTIONet_assess_enrichment`, scores, associations, thread_no)
}

#' Computes the maximum-weight bipartite graph matching
#'
#' @param G Adjacency matrix of the input graph
#'
#' @return G_matched An adjacency matrix with a maximum of one nonzero entry on
#' rows/columns
#'
#' @examples
#' G_matched = MWM_hungarian(G)
MWM_hungarian <- function(G) {
    .Call(`_ACTIONet_MWM_hungarian`, G)
}

MWM_rank1 <- function(u, v, u_threshold = 0, v_threshold = 0) {
    .Call(`_ACTIONet_MWM_rank1`, u, v, u_threshold, v_threshold)
}

run_LPA <- function(G, labels, lambda = 1, iters = 3L, sig_threshold = 3, fixed_labels_ = NULL, thread_no = 0L) {
    .Call(`_ACTIONet_run_LPA`, G, labels, lambda, iters, sig_threshold, fixed_labels_, thread_no)
}

compute_marker_aggregate_stats <- function(G, S, marker_mat, alpha = 0.85, max_it = 5L, thread_no = 0L, ignore_baseline_expression = FALSE) {
    .Call(`_ACTIONet_compute_marker_aggregate_stats`, G, S, marker_mat, alpha, max_it, thread_no, ignore_baseline_expression)
}

LSI <- function(X, size_factor = 100000) {
    .Call(`_ACTIONet_LSI`, X, size_factor)
}

autocorrelation_Geary <- function(G, scores, normalization_method = 1L, perm_no = 30L, thread_no = 0L) {
    .Call(`_ACTIONet_autocorrelation_Geary`, G, scores, normalization_method, perm_no, thread_no)
}

autocorrelation_Geary_full <- function(G, scores, normalization_method = 1L, perm_no = 30L, thread_no = 0L) {
    .Call(`_ACTIONet_autocorrelation_Geary_full`, G, scores, normalization_method, perm_no, thread_no)
}

autocorrelation_Moran <- function(G, scores, normalization_method = 1L, perm_no = 30L, thread_no = 0L) {
    .Call(`_ACTIONet_autocorrelation_Moran`, G, scores, normalization_method, perm_no, thread_no)
}

autocorrelation_Moran_full <- function(G, scores, normalization_method = 1L, perm_no = 30L, thread_no = 0L) {
    .Call(`_ACTIONet_autocorrelation_Moran_full`, G, scores, normalization_method, perm_no, thread_no)
}

#' Computes network diffusion over a given network, starting with an arbitrarty
#' set of initial scores
#'
#' @param G Input graph
#' @param X0 Matrix of initial values per diffusion (ncol(G) == nrow(G) == ncol(X0))
#' @param thread_no Number of parallel threads (default=0)
#' @param alpha Random-walk depth ( between [0, 1] ) ' @param max_it PageRank iterations
#'
#' @return Matrix of diffusion scores
#'
#' @examples
#' G = colNets(ace)$ACTIONet
#' gene.expression = Matrix::t(logcounts(ace))[c("CD19", "CD14", "CD16"), ]
#' smoothed.expression = compute_network_diffusion_approx(G, gene.expression)
compute_network_diffusion_approx <- function(G, X0, thread_no = 0L, alpha = 0.85, max_it = 5L, res_threshold = 1e-8, norm_type = 0L) {
    .Call(`_ACTIONet_compute_network_diffusion_approx`, G, X0, thread_no, alpha, max_it, res_threshold, norm_type)
}

aggregate_genesets_mahalanobis_2archs <- function(G, S, marker_mat, network_normalization_method = 0L, expression_normalization_method = 0L, gene_scaling_method = 0L, pre_alpha = 0.85, post_alpha = 0.85, thread_no = 0L) {
    .Call(`_ACTIONet_aggregate_genesets_mahalanobis_2archs`, G, S, marker_mat, network_normalization_method, expression_normalization_method, gene_scaling_method, pre_alpha, post_alpha, thread_no)
}

aggregate_genesets_mahalanobis_2gmm <- function(G, S, marker_mat, network_normalization_method = 0L, expression_normalization_method = 0L, gene_scaling_method = 0L, pre_alpha = 0.85, post_alpha = 0.85, thread_no = 0L) {
    .Call(`_ACTIONet_aggregate_genesets_mahalanobis_2gmm`, G, S, marker_mat, network_normalization_method, expression_normalization_method, gene_scaling_method, pre_alpha, post_alpha, thread_no)
}

normalize_mat <- function(X, p = 0L, dim = 0L) {
    .Call(`_ACTIONet_normalize_mat`, X, p, dim)
}

normalize_spmat <- function(X, p = 0L, dim = 0L) {
    .Call(`_ACTIONet_normalize_spmat`, X, p, dim)
}

xicor <- function(xvec, yvec, compute_pval = TRUE, seed = 0L) {
    .Call(`_ACTIONet_xicor`, xvec, yvec, compute_pval, seed)
}

XICOR <- function(X, Y, compute_pval = TRUE, seed = 0L, thread_no = 0L) {
    .Call(`_ACTIONet_XICOR`, X, Y, compute_pval, seed, thread_no)
}

aggregate_genesets <- function(G, S, marker_mat, network_normalization_method = 0L, alpha = 0.85, thread_no = 0L) {
    .Call(`_ACTIONet_aggregate_genesets`, G, S, marker_mat, network_normalization_method, alpha, thread_no)
}

assess_label_enrichment <- function(G, M, thread_no = 0L) {
    .Call(`_ACTIONet_assess_label_enrichment`, G, M, thread_no)
}

autocorrelation_Moran_parametric_full <- function(G, scores, normalization_method = 4L, thread_no = 0L) {
    .Call(`_ACTIONet_autocorrelation_Moran_parametric_full`, G, scores, normalization_method, thread_no)
}

autocorrelation_Moran_parametric <- function(G, scores, normalization_method = 4L, thread_no = 0L) {
    .Call(`_ACTIONet_autocorrelation_Moran_parametric`, G, scores, normalization_method, thread_no)
}

# Register entry points for exported C++ functions
methods::setLoadAction(function(ns) {
    .Call(`_ACTIONet_RcppExport_registerCCallable`)
})
